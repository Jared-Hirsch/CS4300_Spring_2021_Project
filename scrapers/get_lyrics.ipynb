{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "posted-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lyricsgenius import Genius\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import string\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from time import time\n",
    "from utils import *\n",
    "import unidecode\n",
    "\n",
    "\n",
    "#TODO: REPLACE WITH LOCAL PATH\n",
    "path = r'REPLACE WITH LOCAL PATH'\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "punct = set(string.punctuation)\n",
    "punct.update({\"''\", \"``\", \"â€™\"})\n",
    "#TODO: REPLACE WITH YOUR OWN KEY\n",
    "key = 'REPLACE WITH YOUR OWN KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "grateful-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetLyrics():\n",
    "    def __init__(self, df, genius_key = key, processed_songs = None):\n",
    "        self.genius_key = key\n",
    "        self.genius = Genius(self.genius_key, verbose=False, retries = 5)\n",
    "        self.df = df\n",
    "        self.song_lyrics = dict()\n",
    "        if processed_songs:\n",
    "            self.processed_songs = processed_songs\n",
    "        else:\n",
    "            self.processed_songs = set()\n",
    "    \n",
    "    def extract_annotations(self, song_id):\n",
    "        ants = self.genius.song_annotations(song_id)\n",
    "        if len(ants) == 0:\n",
    "            return \"\"\n",
    "        \n",
    "        out = []\n",
    "        for line in ants:\n",
    "            for a in line[1]:\n",
    "                out.append(a[0])\n",
    "        return \" \".join(out).lower()\n",
    "\n",
    "\n",
    "    def get_lyrics(self, get_annotations = True):\n",
    "        start_time = time()\n",
    "\n",
    "        \n",
    "        artists_not_found, songs_not_found, songs_found = 0, 0, 0\n",
    "        index = 0\n",
    "        \n",
    "        gb = self.df.groupby('primary_artist')\n",
    "        pbar = tqdm(total = len(gb), desc = \"0\")\n",
    "        for artist_name, subset in gb:\n",
    "            artist_obj = self.genius.search_artist(artist_name, max_songs=0)\n",
    "            if artist_obj is None:\n",
    "                print(f\"{artist_name} not found\")\n",
    "                artists_not_found += 1\n",
    "            else:\n",
    "                for _, row in subset.iterrows():\n",
    "                    index += 1\n",
    "                    uri = row['track_id']\n",
    "                    if uri not in self.processed_songs and uri not in self.song_lyrics:\n",
    "                        song_name = strip_name(row['track_name'])\n",
    "                        song_obj = artist_obj.song(song_name)\n",
    "                        if song_obj is None or not match(artist_name, song_obj.artist):\n",
    "                            songs_not_found += 1\n",
    "                        else:\n",
    "                            lyrics = song_obj.to_text().lower()\n",
    "                            if get_annotations:\n",
    "                                lyrics += self.extract_annotations(song_obj.id)\n",
    "                            lyrics = re.sub(r'[\\(\\[].*?[\\)\\]]', '', lyrics)\n",
    "                            lyrics = os.linesep.join([s for s in lyrics.splitlines() if s])\n",
    "                            tokens = [t for t in tokenizer.tokenize(lyrics) if t not in punct]\n",
    "                            cnt = Counter(tokens)\n",
    "                            self.song_lyrics[uri] = cnt\n",
    "                            songs_found += 1 \n",
    "                if index != 0:\n",
    "                    success_rate = round(songs_found / index, 4)\n",
    "                 \n",
    "                pbar.set_description(f\"{index}; {success_rate}\", refresh=True)            \n",
    "            pbar.update(1)\n",
    "        return self.song_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vanilla-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "df = pd.read_csv(path + \"REPLACE WITH DATASET NAME\")\n",
    "df['primary_artist'] = [unidecode.unidecode(row['artist_name'].split(\",\")[0]) for _, row in df.iterrows()]\n",
    "scraper = GetLyrics(df = df, genius_key = key)\n",
    "lyrics = scraper.get_lyrics(get_annotations = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lyrics, open(\"REPLACE WITH OUTPUT FILE NAME\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
